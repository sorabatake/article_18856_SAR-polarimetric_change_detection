{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変化検出およびコヒーレンス検出\n",
    "\n",
    "SAR画像の取り出しについてはSAR_get.ipynbを参照してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なライブラリの呼び出しと対象のSAR画像のtarget_idを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import leastsq\n",
    "import scipy, scipy.fftpack\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import inf\n",
    "import numpy as np\n",
    "\n",
    "target_id1 = 'SAR_tokyo/ALOS2267472890-190507'\n",
    "target_id2 = 'SAR_tokyo/ALOS2250912890-190115'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 変化検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ripoc(a, b, m = None):\n",
    "    g_a = np.asarray(cv2.cvtColor(a, cv2.COLOR_BGR2GRAY), 'float')\n",
    "    g_b = np.asarray(cv2.cvtColor(b, cv2.COLOR_BGR2GRAY), 'float')\n",
    "\n",
    "    h, w = g_a.shape\n",
    "    hy = np.hanning(h)\n",
    "    hx = np.hanning(w)\n",
    "    hw = hy.reshape(h, 1)*hx\n",
    "    \n",
    "    f_a = np.fft.fftshift(np.log(np.abs(np.fft.fft2(g_a*hw))))\n",
    "    f_b = np.fft.fftshift(np.log(np.abs(np.fft.fft2(g_b*hw))))\n",
    "\n",
    "    if not m:\n",
    "        l = np.sqrt(w*w + h*h)\n",
    "        m = l/np.log(l)\n",
    "\n",
    "    center = (w/2, h/2)\n",
    "    flags = cv2.INTER_LANCZOS4 + cv2.WARP_POLAR_LOG\n",
    "    p_a = cv2.warpPolar(f_a, (w, h), center, m, flags)\n",
    "    p_b = cv2.warpPolar(f_b, (w, h), center, m, flags)\n",
    "    (x, y), e = cv2.phaseCorrelate(p_a, p_b, hw)\n",
    "\n",
    "    angle = y*360/h\n",
    "    scale = (np.e)**(x/m)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    t_b = cv2.warpAffine((g_b), M, (w, h))\n",
    "    (x, y), e = cv2.phaseCorrelate(g_a, t_b)\n",
    "\n",
    "    return x, y, angle, scale\n",
    "\n",
    "def scatter_normalize(data):\n",
    "    data = 10*np.log10(data) -83.0 -32.0\n",
    "    data = np.array(255*(data-np.amin(data))/(np.amax(data)-np.amin(data)),dtype=\"uint8\")\n",
    "    return data\n",
    "\n",
    "def make_image(HH_path,HV_path,VV_path,flag):\n",
    "    Shh = scatter_normalize(np.load(HH_path))\n",
    "    Shv = scatter_normalize(np.load(HV_path))\n",
    "    Svv = scatter_normalize(np.load(VV_path))\n",
    "    img=np.zeros((2000, 2000, 3), np.uint8)\n",
    "    img[:,:,0]=Shh\n",
    "    img[:,:,1]=Shv\n",
    "    img[:,:,2]=Svv\n",
    "    return cv2.flip(img, flag)\n",
    "\n",
    "def registration(img1,img2,flag):\n",
    "    # 位置合わせをしなかったとき\n",
    "    if flag==0:\n",
    "        sigma = np.array(img1,dtype=float)-np.array(img2,dtype=float)\n",
    "        img = np.array(255*(sigma-np.amin(sigma))/(np.amax(sigma)-np.amin(sigma)),dtype=\"uint8\")\n",
    "        plt.imshow(img)\n",
    "        plt.imsave('raw_change.png', img)\n",
    "    # 位置合わせを行うとき\n",
    "    if flag==1:\n",
    "        x, y, angle, scale = ripoc(img1, img2)\n",
    "        print(x, y, angle, scale)\n",
    "\n",
    "        h, w, ch = img1.shape\n",
    "        M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
    "        M[0][2] -= x\n",
    "        M[1][2] -= y\n",
    "        dst = cv2.warpAffine(img2, M, (w, h))\n",
    "        \n",
    "        sigma = np.array(img1,dtype=float)-np.array(dst,dtype=float)\n",
    "        img = np.array(255*(sigma-np.amin(sigma))/(np.amax(sigma)-np.amin(sigma)),dtype=\"uint8\")\n",
    "        plt.imshow(img)\n",
    "        plt.imsave('ripoc_change.png', img)\n",
    "        return M, h, w\n",
    "        \n",
    "img1 = make_image('/home/jovyan/work/'+ target_id1 + '/HH.npy',\n",
    "            '/home/jovyan/work/'+ target_id1 + '/HV.npy',\n",
    "            '/home/jovyan/work/'+ target_id1 + '/VV.npy',\n",
    "            1)\n",
    "img2 = make_image('/home/jovyan/work/'+ target_id2 + '/HH.npy',\n",
    "            '/home/jovyan/work/'+ target_id2 + '/HV.npy',\n",
    "            '/home/jovyan/work/'+ target_id2 + '/VV.npy',\n",
    "            1)\n",
    "registration(img1,img2,0)\n",
    "\n",
    "# このパラメータを使ってSARの生データの位置合わせを行います。\n",
    "M, h, w = registration(img1,img2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAR画像(RAWデータ)の位置合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine(data, M, h, w):\n",
    "    # 8bitに正規化しないとRIPOCが上手く行かないので、\n",
    "    # 正規化した方で変換パラメータだけ取得して、生データに対して変換パラメータを適応させる\n",
    "    result = np.zeros((np.shape(data)[0],np.shape(data)[1]), dtype=np.complex)\n",
    "    result.real = cv2.warpAffine(data.real, M, (w, h))\n",
    "    result.imag = cv2.warpAffine(data.imag, M, (w, h))\n",
    "    return result\n",
    "\n",
    "def make_raw_image(HH,HV,VV,flag):\n",
    "    Shh = 10*np.log10(HH) -83.0 -32.0\n",
    "    Shv = 10*np.log10(HV) -83.0 -32.0\n",
    "    Svv = 10*np.log10(VV) -83.0 -32.0\n",
    "    img=np.zeros((2000, 2000, 3), np.uint8)\n",
    "    img[:,:,0]=Shh\n",
    "    img[:,:,1]=Shv\n",
    "    img[:,:,2]=Svv\n",
    "    return cv2.flip(img, flag)\n",
    "\n",
    "# SARのRAWデータの読み込み\n",
    "HH1 = np.load('/home/jovyan/work/'+ target_id1 + '/HH.npy')\n",
    "HV1 = np.load('/home/jovyan/work/'+ target_id1 + '/HV.npy')\n",
    "VV1 = np.load('/home/jovyan/work/'+ target_id1 + '/VV.npy')\n",
    "HH2 = np.load('/home/jovyan/work/'+ target_id2 + '/HH.npy')\n",
    "HV2 = np.load('/home/jovyan/work/'+ target_id2 + '/HV.npy')\n",
    "VV2 = np.load('/home/jovyan/work/'+ target_id2 + '/VV.npy')\n",
    "\n",
    "# slaveの生のSAR画像の位置合わせを行う\n",
    "t_HH2 = affine(HH2, M, h, w)\n",
    "t_HV2 = affine(HV2, M, h, w)\n",
    "t_VV2 = affine(VV2, M, h, w)\n",
    "\n",
    "master = make_raw_image(HH1,HV1,VV1,1)\n",
    "slave = make_raw_image(t_HH2,t_HV2,t_VV2,1)\n",
    "\n",
    "sigma = np.array(master,dtype=float)-np.array(slave,dtype=float)\n",
    "img = np.array(255*(sigma-np.amin(sigma))/(np.amax(sigma)-np.amin(sigma)),dtype=\"uint8\")\n",
    "plt.imshow(img)\n",
    "plt.imsave('change_SAR_complex.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARの生データのレジストレーション\n",
    "HH1 = np.load('/home/jovyan/work/'+ target_id1 + '/HH.npy')\n",
    "HV1 = np.load('/home/jovyan/work/'+ target_id1 + '/HV.npy')\n",
    "VV1 = np.load('/home/jovyan/work/'+ target_id1 + '/VV.npy')\n",
    "HH2 = np.load('/home/jovyan/work/'+ target_id2 + '/HH.npy')\n",
    "HV2 = np.load('/home/jovyan/work/'+ target_id2 + '/HV.npy')\n",
    "VV2 = np.load('/home/jovyan/work/'+ target_id2 + '/VV.npy')\n",
    "\n",
    "def affine(data, M, h, w):\n",
    "    # 8bitに正規化しないとRIPOCが上手く行かないので、\n",
    "    # 正規化した方で変換パラメータだけ取得して、生データに対して変換パラメータを適応させる\n",
    "    result = np.zeros((np.shape(data)[0],np.shape(data)[1]), dtype=np.complex)\n",
    "    result.real = cv2.warpAffine(data.real, M, (w, h))\n",
    "    result.imag = cv2.warpAffine(data.imag, M, (w, h))\n",
    "    return result\n",
    "\n",
    "# slaveの生のSAR画像の位置合わせを行う\n",
    "t_HH2 = affine(HH2, M, h, w)\n",
    "t_HV2 = affine(HV2, M, h, w)\n",
    "t_VV2 = affine(VV2, M, h, w)\n",
    "\n",
    "#flag = 0: 上下反転\n",
    "#flag > 0: 左右反転\n",
    "#flag < 0: 上下左右反転\n",
    "def make_raw_image(HH,HV,VV,flag):\n",
    "    Shh = 10*np.log10(HH) -83.0 -32.0\n",
    "    Shv = 10*np.log10(HV) -83.0 -32.0\n",
    "    Svv = 10*np.log10(VV) -83.0 -32.0\n",
    "    img=np.zeros((2000, 2000, 3), np.uint8)\n",
    "    img[:,:,0]=Shh\n",
    "    img[:,:,1]=Shv\n",
    "    img[:,:,2]=Svv\n",
    "    return cv2.flip(img, flag)\n",
    "\n",
    "master = make_raw_image(HH1,HV1,VV1,1)\n",
    "slave = make_raw_image(t_HH2,t_HV2,t_VV2,1)\n",
    "\n",
    "sigma = np.array(master,dtype=float)-np.array(slave,dtype=float)\n",
    "# 一番最後に8bitの正規化を行う(どちらにせよ、これをやらないとエラーになる)\n",
    "img = np.array(255*(sigma-np.amin(sigma))/(np.amax(sigma)-np.amin(sigma)),dtype=\"uint8\")\n",
    "plt.imshow(img)\n",
    "plt.imsave('change_SAR_complex.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相関最大化アルゴリズムの適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complex_coherence(Shh1,Shv1,Svv1,Shh2,Shv2,Svv2,x,y):\n",
    "    \n",
    "    T11 = np.zeros((x,y,3,3), dtype=np.complex)\n",
    "    T22 = np.zeros((x,y,3,3), dtype=np.complex)\n",
    "    Omega12 = np.zeros((x,y,3,3), dtype=np.complex)\n",
    "    \n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            k11 = Shh1[i,j]+Svv1[i,j]\n",
    "            k12 = Svv1[i,j]-Shh1[i,j]\n",
    "            k13 = 2*Shv1[i,j]\n",
    "            k21 = Shh2[i,j]+Svv2[i,j]\n",
    "            k22 = Svv2[i,j]-Shh2[i,j]\n",
    "            k23 = 2*Shv2[i,j]\n",
    "            \n",
    "            k1 = np.array([k11, k12, k13]).reshape(3,1)\n",
    "            k2 = np.array([k21, k22, k23]).reshape(3,1)\n",
    "            \n",
    "            # T11は3x3行列でなければならない\n",
    "            T11[i,j,:,:] = np.outer(k1, np.conjugate(k1).T)\n",
    "            T22[i,j,:,:] = np.outer(k2, np.conjugate(k2).T)\n",
    "            Omega12[i,j,:,:] = np.outer(k1,np.conjugate(k2).T)\n",
    "            \n",
    "    result = np.zeros((x,y), dtype=np.complex)\n",
    "    for i in range(x):\n",
    "        for j in range(y):     \n",
    "            Sigma = np.dot(np.dot(np.sqrt(T11[i,j,:,:]),Omega12[i,j,:,:]),np.sqrt(T22[i,j,:,:]))\n",
    "            U, S, V = np.linalg.svd(Sigma, full_matrices=False)\n",
    "            result[i,j] = np.dot(np.dot(np.conjugate(U[0]).T,Omega12[i,j,:,:]),V[0])\n",
    "    return result\n",
    "\n",
    "result = Complex_coherence(HH1,HV1,VV1,t_HH2,t_HV2,t_VV2,np.shape(HH1)[0],np.shape(HH1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コヒーレンスの高い地域を可視化\n",
    "coh = 10*np.log10(abs(result)) -83.0 -32.0\n",
    "coh = np.angle(np.array(coh, dtype=np.complex64))\n",
    "coh[coh == -inf] = 0\n",
    "coh = np.array(255*(coh-np.amin(coh))/(np.amax(coh)-np.amin(coh)),dtype=\"uint8\")\n",
    "\n",
    "img = cv2.flip(np.array(coh, dtype=np.float64), 1)\n",
    "plt.imshow(np.array(img, dtype=np.float64))\n",
    "plt.imsave('coherence_result.jpg', img, cmap = \"jet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
